{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Zenith vs PyTorch: 1GB Dataset Benchmark\n",
                "\n",
                "**Large-scale benchmark with synthetic 1GB dataset**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install pyarrow torch --quiet\n",
                "print(\"Dependencies installed\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Generate 1GB Synthetic Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import pyarrow as pa\n",
                "import pyarrow.parquet as pq\n",
                "import os\n",
                "import gc\n",
                "\n",
                "print(\"Generating 1GB synthetic dataset...\")\n",
                "\n",
                "NUM_SAMPLES = 100000\n",
                "IMG_SHAPE = (3, 32, 32)\n",
                "NUM_CLASSES = 10\n",
                "\n",
                "print(f\"Samples: {NUM_SAMPLES:,}\")\n",
                "print(f\"Expected size: ~{NUM_SAMPLES * np.prod(IMG_SHAPE) * 4 / 1e9:.1f} GB\")\n",
                "\n",
                "# Generate in chunks\n",
                "chunk_size = 10000\n",
                "all_images = []\n",
                "all_labels = []\n",
                "\n",
                "for i in range(0, NUM_SAMPLES, chunk_size):\n",
                "    n = min(chunk_size, NUM_SAMPLES - i)\n",
                "    imgs = np.random.rand(n, *IMG_SHAPE).astype(np.float32)\n",
                "    lbls = np.random.randint(0, NUM_CLASSES, n)\n",
                "    all_images.append(imgs)\n",
                "    all_labels.append(lbls)\n",
                "    print(f\"  Generated {i+n:,}/{NUM_SAMPLES:,}\")\n",
                "\n",
                "images_np = np.concatenate(all_images)\n",
                "labels_np = np.concatenate(all_labels)\n",
                "\n",
                "print(f\"\\nTotal shape: {images_np.shape}\")\n",
                "print(f\"Memory: {images_np.nbytes / 1e9:.2f} GB\")\n",
                "\n",
                "del all_images, all_labels\n",
                "gc.collect()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save as Parquet\n",
                "print(\"Saving to Parquet...\")\n",
                "\n",
                "table = pa.table({\n",
                "    'image': pa.array([img.tobytes() for img in images_np]),\n",
                "    'label': pa.array(labels_np, type=pa.int64())\n",
                "})\n",
                "\n",
                "pq.write_table(table, 'synthetic_1gb.parquet', compression='snappy')\n",
                "\n",
                "size_mb = os.path.getsize('synthetic_1gb.parquet') / (1024**2)\n",
                "print(f\"Saved: synthetic_1gb.parquet ({size_mb:.0f} MB)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Define Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "\n",
                "class SimpleCNN(nn.Module):\n",
                "    def __init__(self):\n",
                "        super().__init__()\n",
                "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
                "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
                "        self.pool = nn.MaxPool2d(2, 2)\n",
                "        self.fc1 = nn.Linear(64 * 8 * 8, 256)\n",
                "        self.fc2 = nn.Linear(256, 10)\n",
                "    \n",
                "    def forward(self, x):\n",
                "        x = self.pool(F.relu(self.conv1(x)))\n",
                "        x = self.pool(F.relu(self.conv2(x)))\n",
                "        x = x.reshape(-1, 64 * 8 * 8)\n",
                "        x = F.relu(self.fc1(x))\n",
                "        return self.fc2(x)\n",
                "\n",
                "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
                "print(f\"Device: {device}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Benchmark: Zenith DataLoader"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import time\n",
                "import torch.optim as optim\n",
                "\n",
                "class ZenithDataLoader:\n",
                "    def __init__(self, path, batch_size=256):\n",
                "        self.table = pq.read_table(path, memory_map=True)\n",
                "        self.batch_size = batch_size\n",
                "        self.num_rows = self.table.num_rows\n",
                "    \n",
                "    def __iter__(self):\n",
                "        indices = np.arange(self.num_rows)\n",
                "        np.random.shuffle(indices)\n",
                "        for start in range(0, self.num_rows, self.batch_size):\n",
                "            end = min(start + self.batch_size, self.num_rows)\n",
                "            yield self.table.take(indices[start:end])\n",
                "    \n",
                "    def __len__(self):\n",
                "        return (self.num_rows + self.batch_size - 1) // self.batch_size\n",
                "\n",
                "print(\"=\"*50)\n",
                "print(\"ZENITH DATALOADER - 1GB DATASET\")\n",
                "print(\"=\"*50)\n",
                "\n",
                "zenith_loader = ZenithDataLoader('synthetic_1gb.parquet', batch_size=256)\n",
                "model = SimpleCNN().to(device)\n",
                "criterion = nn.CrossEntropyLoss()\n",
                "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
                "\n",
                "zenith_times = []\n",
                "for epoch in range(3):\n",
                "    model.train()\n",
                "    start = time.time()\n",
                "    total_loss = 0\n",
                "    \n",
                "    for batch in zenith_loader:\n",
                "        img_bytes = batch.column('image').to_pylist()\n",
                "        lbl_np = batch.column('label').to_numpy()\n",
                "        \n",
                "        img_np = np.array([np.frombuffer(b, dtype=np.float32).reshape(3, 32, 32) \n",
                "                          for b in img_bytes])\n",
                "        \n",
                "        imgs = torch.from_numpy(img_np).to(device)\n",
                "        lbls = torch.from_numpy(lbl_np).long().to(device)\n",
                "        \n",
                "        optimizer.zero_grad()\n",
                "        loss = criterion(model(imgs), lbls)\n",
                "        loss.backward()\n",
                "        optimizer.step()\n",
                "        total_loss += loss.item()\n",
                "    \n",
                "    elapsed = time.time() - start\n",
                "    zenith_times.append(elapsed)\n",
                "    print(f\"Epoch {epoch+1}: Loss={total_loss/len(zenith_loader):.4f}, Time={elapsed:.2f}s\")\n",
                "\n",
                "zenith_avg = sum(zenith_times[1:]) / len(zenith_times[1:])\n",
                "print(f\"\\nZenith avg: {zenith_avg:.2f}s\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Benchmark: PyTorch DataLoader"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from torch.utils.data import DataLoader as TorchDataLoader, TensorDataset\n",
                "\n",
                "print(\"=\"*50)\n",
                "print(\"PYTORCH DATALOADER - 1GB DATASET\")\n",
                "print(\"=\"*50)\n",
                "\n",
                "# Use the numpy arrays we already have (images_np, labels_np)\n",
                "print(\"Converting to PyTorch tensors...\")\n",
                "images_tensor = torch.from_numpy(images_np)\n",
                "labels_tensor = torch.from_numpy(labels_np).long()\n",
                "\n",
                "torch_loader = TorchDataLoader(\n",
                "    TensorDataset(images_tensor, labels_tensor),\n",
                "    batch_size=256,\n",
                "    shuffle=True,\n",
                "    num_workers=2,\n",
                "    pin_memory=True\n",
                ")\n",
                "\n",
                "model = SimpleCNN().to(device)\n",
                "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
                "\n",
                "torch_times = []\n",
                "for epoch in range(3):\n",
                "    model.train()\n",
                "    start = time.time()\n",
                "    total_loss = 0\n",
                "    \n",
                "    for imgs_batch, lbls_batch in torch_loader:\n",
                "        imgs_batch = imgs_batch.to(device)\n",
                "        lbls_batch = lbls_batch.to(device)\n",
                "        \n",
                "        optimizer.zero_grad()\n",
                "        loss = criterion(model(imgs_batch), lbls_batch)\n",
                "        loss.backward()\n",
                "        optimizer.step()\n",
                "        total_loss += loss.item()\n",
                "    \n",
                "    elapsed = time.time() - start\n",
                "    torch_times.append(elapsed)\n",
                "    print(f\"Epoch {epoch+1}: Loss={total_loss/len(torch_loader):.4f}, Time={elapsed:.2f}s\")\n",
                "\n",
                "torch_avg = sum(torch_times[1:]) / len(torch_times[1:])\n",
                "print(f\"\\nPyTorch avg: {torch_avg:.2f}s\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Final Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\n\" + \"=\"*50)\n",
                "print(\"BENCHMARK RESULTS - 1GB SYNTHETIC DATASET\")\n",
                "print(\"=\"*50)\n",
                "print(f\"Dataset: {NUM_SAMPLES:,} samples, ~1GB\")\n",
                "print(f\"Batch size: 256\")\n",
                "print(f\"Device: {device}\")\n",
                "print(\"-\"*50)\n",
                "print(f\"Zenith DataLoader:  {zenith_avg:.2f}s per epoch\")\n",
                "print(f\"PyTorch DataLoader: {torch_avg:.2f}s per epoch\")\n",
                "print(\"-\"*50)\n",
                "\n",
                "if zenith_avg < torch_avg:\n",
                "    speedup = torch_avg / zenith_avg\n",
                "    print(f\"Result: Zenith is {speedup:.2f}x faster\")\n",
                "else:\n",
                "    speedup = zenith_avg / torch_avg\n",
                "    print(f\"Result: PyTorch is {speedup:.2f}x faster\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}