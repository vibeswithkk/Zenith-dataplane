{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Zenith vs PyTorch: Large Dataset Benchmark (1GB)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install pyarrow torch --quiet\n",
                "import numpy as np\n",
                "import pyarrow as pa\n",
                "import pyarrow.parquet as pq\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "import torch.optim as optim\n",
                "from torch.utils.data import DataLoader as TorchDataLoader, TensorDataset\n",
                "import time\n",
                "import os\n",
                "print(\"Ready\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Config\n",
                "NUM_SAMPLES = 100000\n",
                "BATCH_SIZE = 256\n",
                "EPOCHS = 3\n",
                "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
                "print(f\"Device: {device}\")\n",
                "print(f\"Samples: {NUM_SAMPLES:,}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Generate data\n",
                "print(\"Generating synthetic data...\")\n",
                "data_images = np.random.rand(NUM_SAMPLES, 3, 32, 32).astype(np.float32)\n",
                "data_labels = np.random.randint(0, 10, NUM_SAMPLES).astype(np.int64)\n",
                "print(f\"Shape: {data_images.shape}, Size: {data_images.nbytes/1e9:.2f} GB\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save as Parquet\n",
                "print(\"Saving Parquet...\")\n",
                "table = pa.table({\n",
                "    'img': [x.tobytes() for x in data_images],\n",
                "    'lbl': data_labels\n",
                "})\n",
                "pq.write_table(table, 'data.parquet')\n",
                "print(f\"Saved: {os.path.getsize('data.parquet')/1e6:.0f} MB\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Model\n",
                "class CNN(nn.Module):\n",
                "    def __init__(self):\n",
                "        super().__init__()\n",
                "        self.c1 = nn.Conv2d(3, 32, 3, padding=1)\n",
                "        self.c2 = nn.Conv2d(32, 64, 3, padding=1)\n",
                "        self.pool = nn.MaxPool2d(2)\n",
                "        self.fc1 = nn.Linear(64*8*8, 256)\n",
                "        self.fc2 = nn.Linear(256, 10)\n",
                "    def forward(self, x):\n",
                "        x = self.pool(F.relu(self.c1(x)))\n",
                "        x = self.pool(F.relu(self.c2(x)))\n",
                "        x = x.reshape(-1, 64*8*8)\n",
                "        return self.fc2(F.relu(self.fc1(x)))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ZENITH BENCHMARK\n",
                "print(\"=\"*50)\n",
                "print(\"ZENITH (Arrow/Parquet)\")\n",
                "print(\"=\"*50)\n",
                "\n",
                "tbl = pq.read_table('data.parquet', memory_map=True)\n",
                "model = CNN().to(device)\n",
                "opt = optim.Adam(model.parameters())\n",
                "crit = nn.CrossEntropyLoss()\n",
                "\n",
                "z_times = []\n",
                "for ep in range(EPOCHS):\n",
                "    model.train()\n",
                "    t0 = time.time()\n",
                "    idx = np.random.permutation(NUM_SAMPLES)\n",
                "    for i in range(0, NUM_SAMPLES, BATCH_SIZE):\n",
                "        batch = tbl.take(idx[i:i+BATCH_SIZE])\n",
                "        imgs = np.array([np.frombuffer(b, np.float32).reshape(3,32,32) for b in batch['img'].to_pylist()])\n",
                "        lbls = batch['lbl'].to_numpy()\n",
                "        x = torch.from_numpy(imgs).to(device)\n",
                "        y = torch.from_numpy(lbls).to(device)\n",
                "        opt.zero_grad()\n",
                "        loss = crit(model(x), y)\n",
                "        loss.backward()\n",
                "        opt.step()\n",
                "    z_times.append(time.time()-t0)\n",
                "    print(f\"Epoch {ep+1}: {z_times[-1]:.2f}s\")\n",
                "\n",
                "z_avg = sum(z_times[1:])/len(z_times[1:])\n",
                "print(f\"Avg: {z_avg:.2f}s\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# PYTORCH BENCHMARK  \n",
                "print(\"\\n\" + \"=\"*50)\n",
                "print(\"PYTORCH DataLoader\")\n",
                "print(\"=\"*50)\n",
                "\n",
                "# Use original numpy arrays\n",
                "pt_loader = TorchDataLoader(\n",
                "    TensorDataset(torch.from_numpy(data_images), torch.from_numpy(data_labels)),\n",
                "    batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True\n",
                ")\n",
                "\n",
                "model = CNN().to(device)\n",
                "opt = optim.Adam(model.parameters())\n",
                "\n",
                "pt_times = []\n",
                "for ep in range(EPOCHS):\n",
                "    model.train()\n",
                "    t0 = time.time()\n",
                "    for x, y in pt_loader:\n",
                "        x, y = x.to(device), y.to(device)\n",
                "        opt.zero_grad()\n",
                "        loss = crit(model(x), y)\n",
                "        loss.backward()\n",
                "        opt.step()\n",
                "    pt_times.append(time.time()-t0)\n",
                "    print(f\"Epoch {ep+1}: {pt_times[-1]:.2f}s\")\n",
                "\n",
                "pt_avg = sum(pt_times[1:])/len(pt_times[1:])\n",
                "print(f\"Avg: {pt_avg:.2f}s\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# RESULTS\n",
                "print(\"\\n\" + \"=\"*50)\n",
                "print(\"RESULTS\")\n",
                "print(\"=\"*50)\n",
                "print(f\"Zenith:  {z_avg:.2f}s\")\n",
                "print(f\"PyTorch: {pt_avg:.2f}s\")\n",
                "if z_avg < pt_avg:\n",
                "    print(f\"Zenith is {pt_avg/z_avg:.2f}x faster\")\n",
                "else:\n",
                "    print(f\"PyTorch is {z_avg/pt_avg:.2f}x faster\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}