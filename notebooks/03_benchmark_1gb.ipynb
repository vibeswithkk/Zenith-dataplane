{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Zenith vs PyTorch: 1GB Dataset Benchmark\n",
                "\n",
                "Official benchmark using zenith-ai package"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install zenith-ai torch pyarrow --quiet\n",
                "import zenith\n",
                "zenith.info()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import pyarrow as pa\n",
                "import pyarrow.parquet as pq\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "import torch.optim as optim\n",
                "from torch.utils.data import DataLoader as TorchDataLoader, TensorDataset\n",
                "import time\n",
                "import os\n",
                "\n",
                "# Config\n",
                "NUM_SAMPLES = 100000\n",
                "BATCH_SIZE = 256\n",
                "EPOCHS = 3\n",
                "device = zenith.auto_device()\n",
                "print(f\"Device: {device}\")\n",
                "print(f\"Samples: {NUM_SAMPLES:,}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Generate 1GB synthetic data\n",
                "print(\"Generating synthetic data...\")\n",
                "data_images = np.random.rand(NUM_SAMPLES, 3, 32, 32).astype(np.float32)\n",
                "data_labels = np.random.randint(0, 10, NUM_SAMPLES).astype(np.int64)\n",
                "print(f\"Shape: {data_images.shape}, Size: {data_images.nbytes/1e9:.2f} GB\")\n",
                "\n",
                "# Save as Parquet\n",
                "print(\"Saving Parquet...\")\n",
                "table = pa.table({\n",
                "    'img': [x.tobytes() for x in data_images],\n",
                "    'lbl': data_labels\n",
                "})\n",
                "pq.write_table(table, 'data_1gb.parquet')\n",
                "print(f\"Saved: {os.path.getsize('data_1gb.parquet')/1e6:.0f} MB\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Model\n",
                "class CNN(nn.Module):\n",
                "    def __init__(self):\n",
                "        super().__init__()\n",
                "        self.c1 = nn.Conv2d(3, 32, 3, padding=1)\n",
                "        self.c2 = nn.Conv2d(32, 64, 3, padding=1)\n",
                "        self.pool = nn.MaxPool2d(2)\n",
                "        self.fc1 = nn.Linear(64*8*8, 256)\n",
                "        self.fc2 = nn.Linear(256, 10)\n",
                "    def forward(self, x):\n",
                "        x = self.pool(F.relu(self.c1(x)))\n",
                "        x = self.pool(F.relu(self.c2(x)))\n",
                "        x = x.reshape(-1, 64*8*8)\n",
                "        return self.fc2(F.relu(self.fc1(x)))\n",
                "\n",
                "print(\"Model defined\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ZENITH BENCHMARK (using official package)\n",
                "print(\"=\"*50)\n",
                "print(\"ZENITH DATALOADER (Official Package)\")\n",
                "print(\"=\"*50)\n",
                "\n",
                "# Use official zenith.DataLoader\n",
                "zenith_loader = zenith.DataLoader(\n",
                "    'data_1gb.parquet',\n",
                "    batch_size=BATCH_SIZE,\n",
                "    shuffle=True,\n",
                "    device=device\n",
                ")\n",
                "\n",
                "model = CNN().to(device)\n",
                "opt = optim.Adam(model.parameters())\n",
                "crit = nn.CrossEntropyLoss()\n",
                "\n",
                "z_times = []\n",
                "for ep in range(EPOCHS):\n",
                "    model.train()\n",
                "    t0 = time.time()\n",
                "    total_loss = 0\n",
                "    \n",
                "    for batch in zenith_loader:\n",
                "        # Use zenith's to_torch() for zero-copy conversion\n",
                "        data = batch.to_numpy()\n",
                "        imgs = np.array([np.frombuffer(b, np.float32).reshape(3,32,32) for b in data['img']])\n",
                "        lbls = data['lbl']\n",
                "        \n",
                "        x = torch.from_numpy(imgs).to(device)\n",
                "        y = torch.from_numpy(lbls).to(device)\n",
                "        \n",
                "        opt.zero_grad()\n",
                "        loss = crit(model(x), y)\n",
                "        loss.backward()\n",
                "        opt.step()\n",
                "        total_loss += loss.item()\n",
                "    \n",
                "    z_times.append(time.time()-t0)\n",
                "    print(f\"Epoch {ep+1}: Loss={total_loss/len(zenith_loader):.4f}, Time={z_times[-1]:.2f}s\")\n",
                "\n",
                "z_avg = sum(z_times[1:])/len(z_times[1:])\n",
                "print(f\"\\nZenith avg: {z_avg:.2f}s\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# PYTORCH BENCHMARK\n",
                "print(\"\\n\" + \"=\"*50)\n",
                "print(\"PYTORCH DATALOADER\")\n",
                "print(\"=\"*50)\n",
                "\n",
                "pt_loader = TorchDataLoader(\n",
                "    TensorDataset(torch.from_numpy(data_images), torch.from_numpy(data_labels)),\n",
                "    batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True\n",
                ")\n",
                "\n",
                "model = CNN().to(device)\n",
                "opt = optim.Adam(model.parameters())\n",
                "\n",
                "pt_times = []\n",
                "for ep in range(EPOCHS):\n",
                "    model.train()\n",
                "    t0 = time.time()\n",
                "    total_loss = 0\n",
                "    \n",
                "    for x, y in pt_loader:\n",
                "        x, y = x.to(device), y.to(device)\n",
                "        opt.zero_grad()\n",
                "        loss = crit(model(x), y)\n",
                "        loss.backward()\n",
                "        opt.step()\n",
                "        total_loss += loss.item()\n",
                "    \n",
                "    pt_times.append(time.time()-t0)\n",
                "    print(f\"Epoch {ep+1}: Loss={total_loss/len(pt_loader):.4f}, Time={pt_times[-1]:.2f}s\")\n",
                "\n",
                "pt_avg = sum(pt_times[1:])/len(pt_times[1:])\n",
                "print(f\"\\nPyTorch avg: {pt_avg:.2f}s\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# RESULTS\n",
                "print(\"\\n\" + \"=\"*50)\n",
                "print(\"BENCHMARK RESULTS - 1GB DATASET\")\n",
                "print(\"=\"*50)\n",
                "print(f\"Zenith version: {zenith.__version__}\")\n",
                "print(f\"Dataset: {NUM_SAMPLES:,} samples (~1GB)\")\n",
                "print(f\"Device: {device}\")\n",
                "print(\"-\"*50)\n",
                "print(f\"Zenith:  {z_avg:.2f}s per epoch\")\n",
                "print(f\"PyTorch: {pt_avg:.2f}s per epoch\")\n",
                "print(\"-\"*50)\n",
                "if z_avg < pt_avg:\n",
                "    print(f\"Zenith is {pt_avg/z_avg:.2f}x faster\")\n",
                "else:\n",
                "    print(f\"PyTorch is {z_avg/pt_avg:.2f}x faster\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}